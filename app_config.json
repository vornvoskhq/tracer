{
  "default_prompt_preset": "bugs-edges",
  "max_tokens": 512,
  "model": "perplexity/sonar",
  "model_prices": {
    "anthropic/claude-3-haiku-20240307": {
      "input": 0.25,
      "output": 1.25
    },
    "anthropic/claude-3.5-haiku": {
      "input": 1.0,
      "output": 5.0
    },
    "cohere/command-r-plus": {
      "input": 3.0,
      "output": 15.0
    },
    "deepseek/deepseek-chat": {
      "input": 0.14,
      "output": 0.28
    },
    "deepseek/deepseek-r1": {
      "input": 0.55,
      "output": 1.1
    },
    "google/gemini-1.5-flash": {
      "input": 0.35,
      "output": 1.05
    },
    "meta-llama/llama-3.1-70b-instruct": {
      "input": 3.5,
      "output": 5.0
    },
    "meta-llama/llama-3.1-8b-instruct": {
      "input": 0.3,
      "output": 0.6
    },
    "mistralai/mistral-nemo": {
      "input": 0.2,
      "output": 0.6
    },
    "mistralai/mistral-small": {
      "input": 0.25,
      "output": 0.25
    },
    "moonshotai/kimi-k2": {
      "input": 1.5,
      "output": 3.0
    },
    "moonshotai/kimi-k2-thinking": {
      "input": 2.0,
      "output": 4.0
    },
    "openai/gpt-4o": {
      "input": 5.0,
      "output": 15.0
    },
    "openai/gpt-4o-mini": {
      "input": 0.15,
      "output": 0.6
    },
    "openrouter/auto": {
      "input": 0.0,
      "output": 0.0
    },
    "perplexity/sonar": {
      "input": 1.0,
      "output": 2.0
    },
    "perplexity/sonar-reasoning": {
      "input": 2.0,
      "output": 4.0
    },
    "qwen/qwen-2.5-7b-instruct": {
      "input": 0.2,
      "output": 0.4
    },
    "qwen/qwen-plus": {
      "input": 0.8,
      "output": 2.4
    }
  },
  "models": [
    "anthropic/claude-3-haiku-20240307",
    "anthropic/claude-3.5-haiku",
    "cohere/command-r-plus",
    "deepseek/deepseek-chat",
    "deepseek/deepseek-r1",
    "google/gemini-1.5-flash",
    "meta-llama/llama-3.1-70b-instruct",
    "meta-llama/llama-3.1-8b-instruct",
    "mistralai/mistral-nemo",
    "mistralai/mistral-small",
    "moonshotai/kimi-k2",
    "moonshotai/kimi-k2-thinking",
    "openai/gpt-4o",
    "openai/gpt-4o-mini",
    "openrouter/auto",
    "perplexity/sonar",
    "perplexity/sonar-reasoning",
    "qwen/qwen-2.5-7b-instruct",
    "qwen/qwen-plus"
  ],
  "presets": {
    "behavior-io": {
      "label": "Behavior + inputs/outputs only",
      "template": "Summarize the behavior of the following function or execution path, focusing strictly on:\n- Inputs (parameters and important global state)\n- Outputs (return values and changes to state)\n- Invariants the function relies on\n\nAvoid restating the code line-by-line.\n\nFunction source or trace context:\n```python\n{code}\n```"
    },
    "bugs-edges": {
      "label": "Potential bugs / edge cases",
      "template": "This code runs a pipeline of several functions: decorrelate, limiter etc. Can you locate where these functions are executed, i want to be able to re-order the functions as needed\n\n\nFunction source or trace context:\n```python\n{code}\n```"
    },
    "concise-tech": {
      "label": "Concise technical summary",
      "template": "You are an expert Python engineer. Summarize the purpose and behavior of the following function in concise, technical prose. Focus on:\n- Overall purpose\n- Key inputs and outputs\n- Important side effects (I/O, network, database, etc.)\n- Non-obvious edge cases or constraints\n\nFunction source or trace context:\n```python\n{code}\n```"
    },
    "entrypoints": {
      "label": "Suggest entry points",
      "template": "You are helping a developer understand a new, black-box Python codebase. You will be given snippets from many .py files in this project.\n\nYour tasks:\n- Identify which file(s) are most likely to act as entrypoints (top-level scripts or main modules).\n- For each candidate entrypoint, briefly explain why it is likely an entrypoint (e.g., has an if __name__ == '__main__' block, defines a main() that parses CLI args, or is clearly the starting script).\n- If there appears to be a thin wrapper script that quickly hands off control to a deeper module or framework, explain that layering and suggest which deeper file is the 'real' place to start reading.\n- Provide a short recommendation section: 'If you want to understand this application, start by reading: ...'.\n\nProject file snippets:\n```text\n{code}\n```"
    },
    "onboarding": {
      "label": "High-level explanation (onboarding)",
      "template": "You are helping onboard a new engineer to this codebase. Explain what the following function or execution path does in clear, approachable language. Focus on:\n- What problem it solves in the overall system\n- How it fits into the execution flow\n- Any assumptions or preconditions\n- Gotchas or areas where changes are risky\n\nFunction source or trace context:\n```python\n{code}\n```"
    },
    "refactor-ai-mess": {
      "label": "Refactor AI-generated / overcomplex code",
      "template": "You are an expert Python engineer. Review the following function or execution slice, which was likely generated or heavily edited by AI. Provide a concise analysis that covers:\n- Where the structure is overcomplicated, redundant, or over-abstracted\n- Any dead code, unused branches, or unnecessary configuration flags\n- Any use of synthetic or fallback data paths that should be removed or made explicit (for technical analysis software, there must be no hidden fake data).\n\nThen propose a refactor plan:\n- How to simplify while preserving behavior and data integrity\n- Which pieces can safely be deleted vs. just reorganized\n- A short checklist of steps to get from the current version to a cleaner one\n\nFunction source or trace context:\n```python\n{code}\n```"
    }
  },
  "temperature": 0.1,
  "ui": {
    "hide_import_rows": false,
    "left_splitter_sizes": [
      422,
      523
    ],
    "left_tree_column_widths": [
      26,
      43,
      20,
      51,
      70,
      191,
      174,
      159,
      183
    ],
    "llm_dialog_size": [
      468,
      318
    ],
    "main_splitter_sizes": [
      842,
      1044
    ],
    "show_caller_column": true,
    "show_phase_column": true,
    "verbose_logging": false
  }
}